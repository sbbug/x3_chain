# Copyright (c) 2020 Horizon Robotics.All Rights Reserved.
#
# The material in this file is confidential and contains trade secrets
# of Horizon Robotics Inc. This is proprietary information owned by
# Horizon Robotics Inc. No part of this work may be disclosed,
# reproduced, copied, transmitted, or used in any way for any purpose,
# without the express written permission of Horizon Robotics Inc.

# 模型转化相关的参数
model_parameters:
  # Caffe浮点网络数据模型文件
  onnx_model: './yolov5s-visible-lwir.onnx'
  # Caffe网络描述文件
#  prototxt: './yolov5_mutil_modal_back.onnx'
  # 指定模型转换过程中是否输出各层的中间结果，如果为True，则输出所有层的中间输出结果，
  layer_out_dump: False
  # 用于设置上板模型输出的layout, 支持NHWC和NCHW, 输入None则使用模型默认格式
  output_layout: NHWC
  # 日志文件的输出控制参数，
  # debug输出模型转换的详细信息
  # info只输出关键信息 
  # warn输出警告和错误级别以上的信息
  log_level: 'debug'
  # 模型转换输出的结果的存放目录
  working_dir: 'model_output'
  # 模型转换输出的用于上板执行的模型文件的名称前缀
  output_model_file_prefix: 'yolov5_mutil_modal_back'


# 模型输入相关参数, 若输入多个节点, 则应使用';'进行分隔, 使用默认缺省设置则写None
input_parameters:
  # (可不填) 模型输入的节点名称, 此名称应与模型文件中的名称一致, 否则会报错, 不填则会使用模型文件中的节点名称
  input_name: 'img;lwir'
  # 网络实际执行时，输入给网络的数据格式，包括 nv12/rgbp/bgrp/yuv444_128/gray/featuremap,
  # 如果输入的数据为yuv444_128, 模型训练用的是rgbp，则hb_mapper将自动插入YUV到RGBP(NCHW)转化操作
  input_type_rt: 'yuv444_128;yuv444_128'
  # 网络训练时输入的数据格式，可选的值为rgbp/bgrp/gray/featuremap/yuv444_128
  input_type_train: 'rgbp;rgbp'
  # 网络输入的预处理方法，主要有以下几种：
  # no_preprocess 不做任何操作
  # mean_file 减去从通道均值文件(mean_file)得到的均值
  # data_scale 对图像像素乘以data_scale系数
  # mean_file_and_scale 减去通道均值后再乘以scale系数
  norm_type: 'data_scale;data_scale'
  # (可不填) 模型网络的输入大小, 以'x'分隔, 不填则会使用模型文件中的网络输入大小
  input_shape: '1x3x672x672;1x3x672x672'
  # 图像减去的均值存放文件, 文件内存放的如果是通道均值，均值之间必须用空格分隔
  mean_value: 0 0 0;0 0 0
  # 图像预处理缩放比例，该数值应为浮点数
  scale_value: 0.003921568627451 0.003921568627451 0.003921568627451;0.003921568627451 0.003921568627451 0.003921568627451


calibration_parameters:
  # 模型量化的参考图像的存放目录，图片格式支持Jpeg、Bmp等格式，输入的图片
  # 应该是使用的典型场景，一般是从测试集中选择20~50张图片，另外输入
  # 的图片要覆盖典型场景，不要是偏僻场景，如过曝光、饱和、模糊、纯黑、纯白等图片
  # 若有多个输入节点, 则应使用';'进行分隔
  cal_data_dir: './calibration_data_rgbp_visible;./calibration_data_rgbp_lwir'
  # 如果输入的图片文件尺寸和模型训练的尺寸不一致时，并且preprocess_on为true，
  # 则将采用默认预处理方法(opencv resize)，
  # 将输入图片缩放或者裁减到指定尺寸，否则，需要用户提前把图片处理为训练时的尺寸
  preprocess_on: False
  # 模型量化的算法类型，支持kl、max，通常采用KL即可满足要求
  calibration_type: 'max'
  # 模型的量化校准方法设置为promoter，mapper会根据calibration的数据对模型进行微调从而提高精度，
  # promoter_level的级别，可选的参数为-1到2，建议按照0到2的顺序实验，满足精度即可停止实验
  # -1: 不进行promoter
  # 0：表示对模型进行轻微调节，精度提高比较小
  # 1：表示相对0对模型调节幅度稍大，精度提高也比较多
  # 2：表示调节比较激进，可能造成精度的大幅提高也可能造成精度下降
  promoter_level: -1


# 编译器相关参数
compiler_parameters:
  # 编译策略，支持bandwidth和latency两种优化模式;
  # bandwidth以优化ddr的访问带宽为目标；
  # latency以优化推理时间为目标
  compile_mode: 'latency'
  # 设置debug为True将打开编译器的debug模式，能够输出性能仿真的相关信息，如帧率、DDR带宽占用等
  debug: False
  # 编译模型指定核数，不指定默认编译单核模型, 若编译双核模型，将下边注释打开即可
  # core_num: 2
  # 设置每个fuction call最大执行时间，单位为us
  # max_time_per_fc: 500
  # 优化等级可选范围为O0~O3
  # O0不做任何优化, 编译速度最快，优化程度最低,
  # O1-O3随着优化等级提高，预期编译后的模型的执行速度会更快，但是所需编译时间也会变长。
  # 推荐用O2做最快验证
  optimize_level: 'O2'
